{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn pyngrok mediapipe opencv-python-headless pillow numpy\n",
        "!pip install python-multipart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LdWDVvhnvNu4",
        "outputId": "7e1c227d-bebc-462b-f2f7-2e6a4e79ebba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.8)\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: protobuf, numpy, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.21 numpy-1.26.4 protobuf-4.25.7 sounddevice-0.5.2\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2xM5AFijXtMgL3Ukjq3uZ58huew_44SPhSzN4w21KYDz7Gykh  # 실제 토큰으로 교체"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EakgzggvPgb",
        "outputId": "08cedfbb-8600-4691-e7c4-89394cbe0895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 디렉토리 생성\n",
        "os.makedirs('www', exist_ok=True)\n",
        "os.makedirs('uploads', exist_ok=True)\n",
        "os.makedirs('registered_faces', exist_ok=True)"
      ],
      "metadata": {
        "id": "g2l2AklgvSt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bl4-l_Gc3cUL",
        "outputId": "5a69a349-9682-4ec3-e1fc-b573c35ca500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.145-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.145-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.145 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile index.html\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"ko\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>안면인식 및 객체인식 시스템</title>\n",
        "    <script crossorigin src=\"https://unpkg.com/react@18/umd/react.production.min.js\"></script>\n",
        "    <script crossorigin src=\"https://unpkg.com/react-dom@18/umd/react-dom.production.min.js\"></script>\n",
        "    <script src=\"https://unpkg.com/@babel/standalone/babel.min.js\"></script>\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "            margin: 0;\n",
        "            padding: 20px;\n",
        "            background-color: #f5f5f5;\n",
        "        }\n",
        "        .container {\n",
        "            max-width: 900px;\n",
        "            margin: 0 auto;\n",
        "            background: white;\n",
        "            padding: 20px;\n",
        "            border-radius: 10px;\n",
        "            box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
        "        }\n",
        "        .camera-container {\n",
        "            position: relative;\n",
        "            margin: 20px 0;\n",
        "            text-align: center;\n",
        "        }\n",
        "        video {\n",
        "            width: 100%;\n",
        "            max-width: 640px;\n",
        "            border: 2px solid #ddd;\n",
        "            border-radius: 8px;\n",
        "        }\n",
        "        canvas {\n",
        "            position: absolute;\n",
        "            top: 0;\n",
        "            left: 50%;\n",
        "            transform: translateX(-50%);\n",
        "            pointer-events: none;\n",
        "        }\n",
        "        .controls {\n",
        "            display: flex;\n",
        "            flex-wrap: wrap;\n",
        "            gap: 10px;\n",
        "            justify-content: center;\n",
        "            margin: 20px 0;\n",
        "        }\n",
        "        button {\n",
        "            padding: 10px 20px;\n",
        "            font-size: 16px;\n",
        "            cursor: pointer;\n",
        "            background-color: #4CAF50;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 5px;\n",
        "            transition: background-color 0.3s;\n",
        "        }\n",
        "        button:hover {\n",
        "            background-color: #45a049;\n",
        "        }\n",
        "        button:disabled {\n",
        "            background-color: #ccc;\n",
        "            cursor: not-allowed;\n",
        "        }\n",
        "        .detect-objects {\n",
        "            background-color: #2196F3;\n",
        "        }\n",
        "        .detect-objects:hover {\n",
        "            background-color: #0b7dda;\n",
        "        }\n",
        "        .recognize-all {\n",
        "            background-color: #FF9800;\n",
        "        }\n",
        "        .recognize-all:hover {\n",
        "            background-color: #e68900;\n",
        "        }\n",
        "        .info-section {\n",
        "            margin: 20px 0;\n",
        "            padding: 15px;\n",
        "            background-color: #f9f9f9;\n",
        "            border-radius: 5px;\n",
        "        }\n",
        "        .error {\n",
        "            color: red;\n",
        "            margin: 10px 0;\n",
        "        }\n",
        "        .success {\n",
        "            color: green;\n",
        "            margin: 10px 0;\n",
        "        }\n",
        "        .form-group {\n",
        "            margin: 10px 0;\n",
        "        }\n",
        "        label {\n",
        "            display: block;\n",
        "            margin-bottom: 5px;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        input[type=\"text\"] {\n",
        "            width: 100%;\n",
        "            padding: 8px;\n",
        "            border: 1px solid #ddd;\n",
        "            border-radius: 4px;\n",
        "        }\n",
        "        .recognition-results {\n",
        "            margin-top: 20px;\n",
        "            padding: 15px;\n",
        "            background-color: #e8f5e9;\n",
        "            border-radius: 5px;\n",
        "        }\n",
        "        .object-results {\n",
        "            margin-top: 20px;\n",
        "            padding: 15px;\n",
        "            background-color: #e3f2fd;\n",
        "            border-radius: 5px;\n",
        "        }\n",
        "        .combined-results {\n",
        "            margin-top: 20px;\n",
        "            padding: 15px;\n",
        "            background-color: #fff3e0;\n",
        "            border-radius: 5px;\n",
        "        }\n",
        "        .object-item {\n",
        "            margin: 10px 0;\n",
        "            padding: 10px;\n",
        "            background-color: white;\n",
        "            border-radius: 5px;\n",
        "            border-left: 4px solid #2196F3;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div id=\"root\"></div>\n",
        "    <script type=\"text/babel\">\n",
        "        const { useState, useRef, useEffect } = React;\n",
        "\n",
        "        function App() {\n",
        "            const [cameraActive, setCameraActive] = useState(false);\n",
        "            const [selectedCamera, setSelectedCamera] = useState('user');\n",
        "            const [devices, setDevices] = useState([]);\n",
        "            const [message, setMessage] = useState('');\n",
        "            const [messageType, setMessageType] = useState('');\n",
        "            const [isRegistering, setIsRegistering] = useState(false);\n",
        "            const [registerName, setRegisterName] = useState('');\n",
        "            const [recognitionResults, setRecognitionResults] = useState(null);\n",
        "            const [objectResults, setObjectResults] = useState(null);\n",
        "            const [combinedResults, setCombinedResults] = useState(null);\n",
        "            const [detectionBoxes, setDetectionBoxes] = useState([]);\n",
        "\n",
        "            const videoRef = useRef(null);\n",
        "            const canvasRef = useRef(null);\n",
        "            const streamRef = useRef(null);\n",
        "\n",
        "            useEffect(() => {\n",
        "                // 카메라 장치 목록 가져오기\n",
        "                navigator.mediaDevices.enumerateDevices()\n",
        "                    .then(devices => {\n",
        "                        const videoDevices = devices.filter(device => device.kind === 'videoinput');\n",
        "                        setDevices(videoDevices);\n",
        "                    });\n",
        "            }, []);\n",
        "\n",
        "            const startCamera = async () => {\n",
        "                try {\n",
        "                    if (streamRef.current) {\n",
        "                        streamRef.current.getTracks().forEach(track => track.stop());\n",
        "                    }\n",
        "\n",
        "                    const constraints = {\n",
        "                        video: { facingMode: selectedCamera }\n",
        "                    };\n",
        "\n",
        "                    const stream = await navigator.mediaDevices.getUserMedia(constraints);\n",
        "                    streamRef.current = stream;\n",
        "\n",
        "                    if (videoRef.current) {\n",
        "                        videoRef.current.srcObject = stream;\n",
        "                        setCameraActive(true);\n",
        "                    }\n",
        "                } catch (error) {\n",
        "                    showMessage('카메라를 시작할 수 없습니다: ' + error.message, 'error');\n",
        "                }\n",
        "            };\n",
        "\n",
        "            const stopCamera = () => {\n",
        "                if (streamRef.current) {\n",
        "                    streamRef.current.getTracks().forEach(track => track.stop());\n",
        "                    streamRef.current = null;\n",
        "                }\n",
        "                if (videoRef.current) {\n",
        "                    videoRef.current.srcObject = null;\n",
        "                }\n",
        "                setCameraActive(false);\n",
        "                setDetectionBoxes([]);\n",
        "                clearCanvas();\n",
        "            };\n",
        "\n",
        "            const captureImage = () => {\n",
        "                if (!videoRef.current) return null;\n",
        "\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = videoRef.current.videoWidth;\n",
        "                canvas.height = videoRef.current.videoHeight;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "                ctx.drawImage(videoRef.current, 0, 0);\n",
        "\n",
        "                return canvas.toDataURL('image/jpeg');\n",
        "            };\n",
        "\n",
        "            const showMessage = (msg, type) => {\n",
        "                setMessage(msg);\n",
        "                setMessageType(type);\n",
        "                setTimeout(() => {\n",
        "                    setMessage('');\n",
        "                    setMessageType('');\n",
        "                }, 5000);\n",
        "            };\n",
        "\n",
        "            const clearCanvas = () => {\n",
        "                if (canvasRef.current) {\n",
        "                    const ctx = canvasRef.current.getContext('2d');\n",
        "                    ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);\n",
        "                }\n",
        "            };\n",
        "\n",
        "            const drawDetectionBoxes = (boxes) => {\n",
        "                if (!canvasRef.current || !videoRef.current) return;\n",
        "\n",
        "                const canvas = canvasRef.current;\n",
        "                const ctx = canvas.getContext('2d');\n",
        "\n",
        "                canvas.width = videoRef.current.offsetWidth;\n",
        "                canvas.height = videoRef.current.offsetHeight;\n",
        "\n",
        "                ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "\n",
        "                boxes.forEach((box, index) => {\n",
        "                    // 색상 설정\n",
        "                    if (box.type === 'face') {\n",
        "                        ctx.strokeStyle = '#00ff00'; // 녹색 - 얼굴\n",
        "                        ctx.fillStyle = '#00ff00';\n",
        "                    } else {\n",
        "                        ctx.strokeStyle = '#ff0000'; // 빨강 - 객체\n",
        "                        ctx.fillStyle = '#ff0000';\n",
        "                    }\n",
        "\n",
        "                    ctx.lineWidth = 3;\n",
        "                    ctx.strokeRect(box.left, box.top, box.width, box.height);\n",
        "\n",
        "                    // 라벨 그리기\n",
        "                    if (box.label) {\n",
        "                        ctx.font = '16px Arial';\n",
        "                        ctx.textAlign = 'left';\n",
        "                        const textY = box.top > 20 ? box.top - 5 : box.top + 20;\n",
        "                        ctx.fillText(box.label, box.left, textY);\n",
        "                    }\n",
        "                });\n",
        "            };\n",
        "\n",
        "            const registerFace = async () => {\n",
        "                if (!registerName.trim()) {\n",
        "                    showMessage('이름을 입력해주세요.', 'error');\n",
        "                    return;\n",
        "                }\n",
        "\n",
        "                const imageData = captureImage();\n",
        "                if (!imageData) {\n",
        "                    showMessage('카메라가 활성화되지 않았습니다.', 'error');\n",
        "                    return;\n",
        "                }\n",
        "\n",
        "                try {\n",
        "                    const formData = new FormData();\n",
        "                    const blob = await fetch(imageData).then(r => r.blob());\n",
        "                    formData.append('image', blob, 'face.jpg');\n",
        "                    formData.append('name', registerName);\n",
        "\n",
        "                    const response = await fetch('./register', {\n",
        "                        method: 'POST',\n",
        "                        body: formData\n",
        "                    });\n",
        "\n",
        "                    const data = await response.json();\n",
        "\n",
        "                    if (response.ok) {\n",
        "                        showMessage(data.message, 'success');\n",
        "                        setRegisterName('');\n",
        "                        setIsRegistering(false);\n",
        "                    } else {\n",
        "                        showMessage(data.detail || '등록 실패', 'error');\n",
        "                    }\n",
        "                } catch (error) {\n",
        "                    showMessage('등록 중 오류 발생: ' + error.message, 'error');\n",
        "                }\n",
        "            };\n",
        "\n",
        "            const recognizeFace = async () => {\n",
        "                const imageData = captureImage();\n",
        "                if (!imageData) {\n",
        "                    showMessage('카메라가 활성화되지 않았습니다.', 'error');\n",
        "                    return;\n",
        "                }\n",
        "\n",
        "                try {\n",
        "                    const formData = new FormData();\n",
        "                    const blob = await fetch(imageData).then(r => r.blob());\n",
        "                    formData.append('image', blob, 'face.jpg');\n",
        "\n",
        "                    const response = await fetch('./recognize', {\n",
        "                        method: 'POST',\n",
        "                        body: formData\n",
        "                    });\n",
        "\n",
        "                    const data = await response.json();\n",
        "\n",
        "                    if (response.ok) {\n",
        "                        setRecognitionResults(data);\n",
        "                        setObjectResults(null);\n",
        "                        setCombinedResults(null);\n",
        "\n",
        "                        const boxes = [];\n",
        "                        if (data.face_detected && videoRef.current) {\n",
        "                            const videoWidth = videoRef.current.videoWidth;\n",
        "                            const videoHeight = videoRef.current.videoHeight;\n",
        "                            const displayWidth = videoRef.current.offsetWidth;\n",
        "                            const displayHeight = videoRef.current.offsetHeight;\n",
        "\n",
        "                            const scaleX = displayWidth / videoWidth;\n",
        "                            const scaleY = displayHeight / videoHeight;\n",
        "\n",
        "                            const rect = data.face_location;\n",
        "                            boxes.push({\n",
        "                                type: 'face',\n",
        "                                left: rect.left * scaleX,\n",
        "                                top: rect.top * scaleY,\n",
        "                                width: rect.width * scaleX,\n",
        "                                height: rect.height * scaleY,\n",
        "                                label: data.recognized ? data.name : 'Unknown'\n",
        "                            });\n",
        "                        }\n",
        "\n",
        "                        setDetectionBoxes(boxes);\n",
        "                        drawDetectionBoxes(boxes);\n",
        "                        showMessage('얼굴 인식 완료', 'success');\n",
        "                    } else {\n",
        "                        showMessage(data.detail || '인식 실패', 'error');\n",
        "                    }\n",
        "                } catch (error) {\n",
        "                    showMessage('인식 중 오류 발생: ' + error.message, 'error');\n",
        "                }\n",
        "            };\n",
        "\n",
        "            const detectObjects = async () => {\n",
        "                const imageData = captureImage();\n",
        "                if (!imageData) {\n",
        "                    showMessage('카메라가 활성화되지 않았습니다.', 'error');\n",
        "                    return;\n",
        "                }\n",
        "\n",
        "                try {\n",
        "                    const formData = new FormData();\n",
        "                    const blob = await fetch(imageData).then(r => r.blob());\n",
        "                    formData.append('image', blob, 'objects.jpg');\n",
        "\n",
        "                    const response = await fetch('./detect_objects', {\n",
        "                        method: 'POST',\n",
        "                        body: formData\n",
        "                    });\n",
        "\n",
        "                    const data = await response.json();\n",
        "\n",
        "                    if (response.ok) {\n",
        "                        setObjectResults(data);\n",
        "                        setRecognitionResults(null);\n",
        "                        setCombinedResults(null);\n",
        "\n",
        "                        const boxes = [];\n",
        "                        if (data.objects_detected && videoRef.current) {\n",
        "                            const videoWidth = videoRef.current.videoWidth;\n",
        "                            const videoHeight = videoRef.current.videoHeight;\n",
        "                            const displayWidth = videoRef.current.offsetWidth;\n",
        "                            const displayHeight = videoRef.current.offsetHeight;\n",
        "\n",
        "                            const scaleX = displayWidth / videoWidth;\n",
        "                            const scaleY = displayHeight / videoHeight;\n",
        "\n",
        "                            data.objects.forEach(obj => {\n",
        "                                boxes.push({\n",
        "                                    type: 'object',\n",
        "                                    left: obj.location.left * scaleX,\n",
        "                                    top: obj.location.top * scaleY,\n",
        "                                    width: obj.location.width * scaleX,\n",
        "                                    height: obj.location.height * scaleY,\n",
        "                                    label: `${obj.name} (${(obj.confidence * 100).toFixed(1)}%)`\n",
        "                                });\n",
        "                            });\n",
        "                        }\n",
        "\n",
        "                        setDetectionBoxes(boxes);\n",
        "                        drawDetectionBoxes(boxes);\n",
        "                        showMessage(data.message, 'success');\n",
        "                    } else {\n",
        "                        showMessage(data.detail || '객체 감지 실패', 'error');\n",
        "                    }\n",
        "                } catch (error) {\n",
        "                    showMessage('객체 감지 중 오류 발생: ' + error.message, 'error');\n",
        "                }\n",
        "            };\n",
        "\n",
        "            const recognizeAll = async () => {\n",
        "                const imageData = captureImage();\n",
        "                if (!imageData) {\n",
        "                    showMessage('카메라가 활성화되지 않았습니다.', 'error');\n",
        "                    return;\n",
        "                }\n",
        "\n",
        "                try {\n",
        "                    const formData = new FormData();\n",
        "                    const blob = await fetch(imageData).then(r => r.blob());\n",
        "                    formData.append('image', blob, 'all.jpg');\n",
        "\n",
        "                    const response = await fetch('./recognize_all', {\n",
        "                        method: 'POST',\n",
        "                        body: formData\n",
        "                    });\n",
        "\n",
        "                    const data = await response.json();\n",
        "\n",
        "                    if (response.ok) {\n",
        "                        setCombinedResults(data);\n",
        "                        setRecognitionResults(null);\n",
        "                        setObjectResults(null);\n",
        "\n",
        "                        const boxes = [];\n",
        "                        if (videoRef.current) {\n",
        "                            const videoWidth = videoRef.current.videoWidth;\n",
        "                            const videoHeight = videoRef.current.videoHeight;\n",
        "                            const displayWidth = videoRef.current.offsetWidth;\n",
        "                            const displayHeight = videoRef.current.offsetHeight;\n",
        "\n",
        "                            const scaleX = displayWidth / videoWidth;\n",
        "                            const scaleY = displayHeight / videoHeight;\n",
        "\n",
        "                            // 얼굴 박스 추가\n",
        "                            if (data.face_info.face_detected) {\n",
        "                                const rect = data.face_info.face_location;\n",
        "                                boxes.push({\n",
        "                                    type: 'face',\n",
        "                                    left: rect.left * scaleX,\n",
        "                                    top: rect.top * scaleY,\n",
        "                                    width: rect.width * scaleX,\n",
        "                                    height: rect.height * scaleY,\n",
        "                                    label: data.face_info.recognized ? data.face_info.name : 'Unknown'\n",
        "                                });\n",
        "                            }\n",
        "\n",
        "                            // 객체 박스 추가\n",
        "                            if (data.objects_info.objects_detected) {\n",
        "                                data.objects_info.objects.forEach(obj => {\n",
        "                                    boxes.push({\n",
        "                                        type: 'object',\n",
        "                                        left: obj.location.left * scaleX,\n",
        "                                        top: obj.location.top * scaleY,\n",
        "                                        width: obj.location.width * scaleX,\n",
        "                                        height: obj.location.height * scaleY,\n",
        "                                        label: `${obj.name} (${(obj.confidence * 100).toFixed(1)}%)`\n",
        "                                    });\n",
        "                                });\n",
        "                            }\n",
        "                        }\n",
        "\n",
        "                        setDetectionBoxes(boxes);\n",
        "                        drawDetectionBoxes(boxes);\n",
        "                        showMessage(data.message, 'success');\n",
        "                    } else {\n",
        "                        showMessage(data.detail || '통합 인식 실패', 'error');\n",
        "                    }\n",
        "                } catch (error) {\n",
        "                    showMessage('통합 인식 중 오류 발생: ' + error.message, 'error');\n",
        "                }\n",
        "            };\n",
        "\n",
        "            useEffect(() => {\n",
        "                if (detectionBoxes.length > 0) {\n",
        "                    drawDetectionBoxes(detectionBoxes);\n",
        "                }\n",
        "            }, [detectionBoxes]);\n",
        "\n",
        "            return (\n",
        "                <div className=\"container\">\n",
        "                    <h1>안면인식 및 객체인식 시스템</h1>\n",
        "\n",
        "                    <div className=\"controls\">\n",
        "                        <select\n",
        "                            value={selectedCamera}\n",
        "                            onChange={(e) => setSelectedCamera(e.target.value)}\n",
        "                            disabled={cameraActive}\n",
        "                        >\n",
        "                            <option value=\"user\">전면 카메라</option>\n",
        "                            <option value=\"environment\">후면 카메라</option>\n",
        "                        </select>\n",
        "\n",
        "                        {!cameraActive ? (\n",
        "                            <button onClick={startCamera}>카메라 시작</button>\n",
        "                        ) : (\n",
        "                            <button onClick={stopCamera}>카메라 중지</button>\n",
        "                        )}\n",
        "                    </div>\n",
        "\n",
        "                    <div className=\"camera-container\">\n",
        "                        <video\n",
        "                            ref={videoRef}\n",
        "                            autoPlay\n",
        "                            playsInline\n",
        "                            style={{ display: cameraActive ? 'block' : 'none' }}\n",
        "                        />\n",
        "                        <canvas\n",
        "                            ref={canvasRef}\n",
        "                            style={{ display: cameraActive ? 'block' : 'none' }}\n",
        "                        />\n",
        "                    </div>\n",
        "\n",
        "                    {message && (\n",
        "                        <div className={messageType === 'error' ? 'error' : 'success'}>\n",
        "                            {message}\n",
        "                        </div>\n",
        "                    )}\n",
        "\n",
        "                    {cameraActive && (\n",
        "                        <div className=\"controls\">\n",
        "                            {!isRegistering ? (\n",
        "                                <>\n",
        "                                    <button onClick={() => setIsRegistering(true)}>안면 등록</button>\n",
        "                                    <button onClick={recognizeFace}>안면 인식</button>\n",
        "                                    <button className=\"detect-objects\" onClick={detectObjects}>객체 감지</button>\n",
        "                                    <button className=\"recognize-all\" onClick={recognizeAll}>전체 인식</button>\n",
        "                                </>\n",
        "                            ) : (\n",
        "                                <div className=\"form-group\">\n",
        "                                    <label>등록할 이름:</label>\n",
        "                                    <input\n",
        "                                        type=\"text\"\n",
        "                                        value={registerName}\n",
        "                                        onChange={(e) => setRegisterName(e.target.value)}\n",
        "                                        placeholder=\"이름을 입력하세요\"\n",
        "                                    />\n",
        "                                    <div className=\"controls\" style={{ marginTop: '10px' }}>\n",
        "                                        <button onClick={registerFace}>등록 완료</button>\n",
        "                                        <button onClick={() => {\n",
        "                                            setIsRegistering(false);\n",
        "                                            setRegisterName('');\n",
        "                                        }}>취소</button>\n",
        "                                    </div>\n",
        "                                </div>\n",
        "                            )}\n",
        "                        </div>\n",
        "                    )}\n",
        "\n",
        "                    {recognitionResults && (\n",
        "                        <div className=\"recognition-results\">\n",
        "                            <h3>얼굴 인식 결과</h3>\n",
        "                            <p>얼굴 감지: {recognitionResults.face_detected ? '예' : '아니오'}</p>\n",
        "                            {recognitionResults.recognized && (\n",
        "                                <>\n",
        "                                    <p>인식된 사람: {recognitionResults.name}</p>\n",
        "                                    <p>신뢰도: {(recognitionResults.confidence * 100).toFixed(2)}%</p>\n",
        "                                </>\n",
        "                            )}\n",
        "                            {recognitionResults.face_detected && (\n",
        "                                <>\n",
        "                                    <p>얼굴 특징점 수: {recognitionResults.num_landmarks}</p>\n",
        "                                    <p>얼굴 위치:\n",
        "                                        상단-{recognitionResults.face_location.top},\n",
        "                                        좌측-{recognitionResults.face_location.left},\n",
        "                                        너비-{recognitionResults.face_location.width},\n",
        "                                        높이-{recognitionResults.face_location.height}\n",
        "                                    </p>\n",
        "                                </>\n",
        "                            )}\n",
        "                        </div>\n",
        "                    )}\n",
        "\n",
        "                    {objectResults && (\n",
        "                        <div className=\"object-results\">\n",
        "                            <h3>객체 감지 결과</h3>\n",
        "                            <p>감지된 객체 수: {objectResults.num_objects}개</p>\n",
        "                            {objectResults.objects_detected && (\n",
        "                                <div>\n",
        "                                    <h4>감지된 객체들:</h4>\n",
        "                                    {objectResults.objects.map((obj, index) => (\n",
        "                                        <div key={index} className=\"object-item\">\n",
        "                                            <strong>{obj.name}</strong> - {(obj.confidence * 100).toFixed(1)}% 신뢰도\n",
        "                                            <br />\n",
        "                                            위치: 좌측-{obj.location.left}, 상단-{obj.location.top},\n",
        "                                            너비-{obj.location.width}, 높이-{obj.location.height}\n",
        "                                        </div>\n",
        "                                    ))}\n",
        "                                </div>\n",
        "                            )}\n",
        "                        </div>\n",
        "                    )}\n",
        "\n",
        "                    {combinedResults && (\n",
        "                        <div className=\"combined-results\">\n",
        "                            <h3>통합 인식 결과</h3>\n",
        "\n",
        "                            <h4>얼굴 정보:</h4>\n",
        "                            <p>얼굴 감지: {combinedResults.face_info.face_detected ? '예' : '아니오'}</p>\n",
        "                            {combinedResults.face_info.recognized && (\n",
        "                                <>\n",
        "                                    <p>인식된 사람: {combinedResults.face_info.name}</p>\n",
        "                                    <p>신뢰도: {(combinedResults.face_info.confidence * 100).toFixed(2)}%</p>\n",
        "                                </>\n",
        "                            )}\n",
        "\n",
        "                            <h4>객체 정보:</h4>\n",
        "                            <p>감지된 객체 수: {combinedResults.objects_info.num_objects}개</p>\n",
        "                            {combinedResults.objects_info.objects_detected && (\n",
        "                                <div>\n",
        "                                    {combinedResults.objects_info.objects.map((obj, index) => (\n",
        "                                        <div key={index} className=\"object-item\">\n",
        "                                            <strong>{obj.name}</strong> - {(obj.confidence * 100).toFixed(1)}% 신뢰도\n",
        "                                        </div>\n",
        "                                    ))}\n",
        "                                </div>\n",
        "                            )}\n",
        "                        </div>\n",
        "                    )}\n",
        "\n",
        "                    <div className=\"info-section\">\n",
        "                        <h3>사용 방법</h3>\n",
        "                        <ul>\n",
        "                            <li><strong>안면 등록:</strong> 새로운 사람의 얼굴을 시스템에 등록합니다.</li>\n",
        "                            <li><strong>안면 인식:</strong> 등록된 사람의 얼굴을 인식합니다.</li>\n",
        "                            <li><strong>객체 감지:</strong> 이미지에서 다양한 객체들을 감지합니다 (커피, 휴대폰, 티슈 등).</li>\n",
        "                            <li><strong>전체 인식:</strong> 얼굴과 객체를 동시에 인식합니다.</li>\n",
        "                        </ul>\n",
        "                        <p><em>녹색 박스: 얼굴, 빨간색 박스: 객체</em></p>\n",
        "                    </div>\n",
        "                </div>\n",
        "            );\n",
        "        }\n",
        "\n",
        "        ReactDOM.render(<App />, document.getElementById('root'));\n",
        "    </script>\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSebqNIq3yln",
        "outputId": "26e9f764-ecdc-41cf-8825-1babaaf44ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing index.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from fastapi import FastAPI, File, UploadFile, Form, HTTPException\n",
        "from fastapi.responses import HTMLResponse, FileResponse\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import base64\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "from typing import Optional\n",
        "import io\n",
        "from PIL import Image\n",
        "import urllib.request\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# CORS 설정\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# MediaPipe 초기화\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
        "\n",
        "# YOLO 모델 초기화\n",
        "YOLO_WEIGHTS_PATH = \"yolov4-tiny.weights\"\n",
        "YOLO_CONFIG_PATH = \"yolov4-tiny.cfg\"\n",
        "YOLO_NAMES_PATH = \"coco.names\"\n",
        "\n",
        "def download_yolo_files():\n",
        "    \"\"\"YOLO 모델 파일 다운로드\"\"\"\n",
        "    urls = {\n",
        "        YOLO_WEIGHTS_PATH: \"https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4-tiny.weights\",\n",
        "        YOLO_CONFIG_PATH: \"https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4-tiny.cfg\",\n",
        "        YOLO_NAMES_PATH: \"https://raw.githubusercontent.com/AlexeyAB/darknet/master/data/coco.names\"\n",
        "    }\n",
        "\n",
        "    for file_path, url in urls.items():\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Downloading from: {url} to {file_path}\")\n",
        "        urllib.request.urlretrieve(url, file_path)\n",
        "        print(f\"{file_path} downloaded successfully!\")\n",
        "\n",
        "# YOLO 파일 다운로드\n",
        "download_yolo_files()\n",
        "\n",
        "# YOLO 모델 로드\n",
        "try:\n",
        "    net = cv2.dnn.readNet(YOLO_WEIGHTS_PATH, YOLO_CONFIG_PATH)\n",
        "    with open(YOLO_NAMES_PATH, \"r\") as f:\n",
        "        classes = [line.strip() for line in f.readlines()]\n",
        "    layer_names = net.getLayerNames()\n",
        "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "    print(\"YOLO model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading YOLO model: {e}\")\n",
        "    net = None\n",
        "    classes = []\n",
        "    output_layers = []\n",
        "\n",
        "# 등록된 얼굴 데이터 저장 경로\n",
        "REGISTERED_FACES_DIR = Path(\"registered_faces\")\n",
        "REGISTERED_FACES_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "def extract_face_embedding(image):\n",
        "    \"\"\"MediaPipe를 사용한 얼굴 특징 추출\"\"\"\n",
        "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = face_mesh.process(rgb_image)\n",
        "\n",
        "    if results.multi_face_landmarks:\n",
        "        face_landmarks = results.multi_face_landmarks[0]\n",
        "\n",
        "        # 랜드마크를 numpy 배열로 변환\n",
        "        landmarks = []\n",
        "        for landmark in face_landmarks.landmark:\n",
        "            landmarks.extend([landmark.x, landmark.y, landmark.z])\n",
        "\n",
        "        return np.array(landmarks)\n",
        "\n",
        "    return None\n",
        "\n",
        "def compare_embeddings(embedding1, embedding2):\n",
        "    \"\"\"두 임베딩 간의 유사도 계산\"\"\"\n",
        "    if embedding1 is None or embedding2 is None:\n",
        "        return 0.0\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    dot_product = np.dot(embedding1, embedding2)\n",
        "    norm1 = np.linalg.norm(embedding1)\n",
        "    norm2 = np.linalg.norm(embedding2)\n",
        "\n",
        "    if norm1 == 0 or norm2 == 0:\n",
        "        return 0.0\n",
        "\n",
        "    similarity = dot_product / (norm1 * norm2)\n",
        "    return similarity\n",
        "\n",
        "def get_face_detection_info(image):\n",
        "    \"\"\"얼굴 감지 정보 추출\"\"\"\n",
        "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = face_detection.process(rgb_image)\n",
        "\n",
        "    if results.detections:\n",
        "        detection = results.detections[0]\n",
        "        bbox = detection.location_data.relative_bounding_box\n",
        "        h, w, _ = image.shape\n",
        "\n",
        "        return {\n",
        "            \"face_detected\": True,\n",
        "            \"face_location\": {\n",
        "                \"left\": int(bbox.xmin * w),\n",
        "                \"top\": int(bbox.ymin * h),\n",
        "                \"width\": int(bbox.width * w),\n",
        "                \"height\": int(bbox.height * h)\n",
        "            }\n",
        "        }\n",
        "\n",
        "    return {\"face_detected\": False}\n",
        "\n",
        "def detect_objects(image):\n",
        "    \"\"\"YOLO를 사용한 객체 감지\"\"\"\n",
        "    if net is None:\n",
        "        return []\n",
        "\n",
        "    height, width, channels = image.shape\n",
        "\n",
        "    # 이미지를 YOLO 입력 형식으로 변환\n",
        "    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    # 정보 추출\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "\n",
        "            if confidence > 0.3:  # 30% 이상 신뢰도\n",
        "                # 객체 위치 계산\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # 사각형 좌표\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Non-maximum suppression 적용\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.3, 0.4)\n",
        "\n",
        "    detected_objects = []\n",
        "    if len(indexes) > 0:\n",
        "        for i in indexes.flatten():\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            confidence = confidences[i]\n",
        "\n",
        "            detected_objects.append({\n",
        "                \"name\": label,\n",
        "                \"confidence\": confidence,\n",
        "                \"location\": {\n",
        "                    \"left\": x,\n",
        "                    \"top\": y,\n",
        "                    \"width\": w,\n",
        "                    \"height\": h\n",
        "                }\n",
        "            })\n",
        "\n",
        "    return detected_objects\n",
        "\n",
        "@app.post(\"/register\")\n",
        "async def register_face(image: UploadFile = File(...), name: str = Form(...)):\n",
        "    \"\"\"얼굴 등록 API\"\"\"\n",
        "    try:\n",
        "        # 이름 검증\n",
        "        if not name.strip():\n",
        "            raise HTTPException(status_code=400, detail=\"이름을 입력해주세요.\")\n",
        "\n",
        "        # 이미지 읽기\n",
        "        contents = await image.read()\n",
        "        nparr = np.frombuffer(contents, np.uint8)\n",
        "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # 얼굴 특징 추출\n",
        "        embedding = extract_face_embedding(img)\n",
        "        if embedding is None:\n",
        "            raise HTTPException(status_code=400, detail=\"얼굴을 찾을 수 없습니다.\")\n",
        "\n",
        "        # 기존 등록된 얼굴과 비교\n",
        "        for file in REGISTERED_FACES_DIR.glob(\"*.pkl\"):\n",
        "            with open(file, \"rb\") as f:\n",
        "                registered_data = pickle.load(f)\n",
        "                registered_embedding = registered_data[\"embedding\"]\n",
        "                similarity = compare_embeddings(embedding, registered_embedding)\n",
        "\n",
        "                if similarity > 0.95:  # 95% 이상 유사도\n",
        "                    raise HTTPException(\n",
        "                        status_code=400,\n",
        "                        detail=f\"이미 등록된 얼굴입니다. (유사도: {similarity*100:.1f}%)\"\n",
        "                    )\n",
        "\n",
        "        # 얼굴 데이터 저장\n",
        "        face_data = {\n",
        "            \"name\": name,\n",
        "            \"embedding\": embedding\n",
        "        }\n",
        "\n",
        "        filename = f\"{name}_{len(list(REGISTERED_FACES_DIR.glob('*.pkl')))}.pkl\"\n",
        "        with open(REGISTERED_FACES_DIR / filename, \"wb\") as f:\n",
        "            pickle.dump(face_data, f)\n",
        "\n",
        "        return {\"message\": f\"{name}님의 얼굴이 성공적으로 등록되었습니다.\"}\n",
        "\n",
        "    except HTTPException:\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/recognize\")\n",
        "async def recognize_face(image: UploadFile = File(...)):\n",
        "    \"\"\"얼굴 인식 API\"\"\"\n",
        "    try:\n",
        "        # 이미지 읽기\n",
        "        contents = await image.read()\n",
        "        nparr = np.frombuffer(contents, np.uint8)\n",
        "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # 얼굴 감지 정보\n",
        "        detection_info = get_face_detection_info(img)\n",
        "\n",
        "        # 얼굴 특징 추출\n",
        "        embedding = extract_face_embedding(img)\n",
        "        if embedding is None:\n",
        "            return {\n",
        "                **detection_info,\n",
        "                \"recognized\": False,\n",
        "                \"message\": \"얼굴을 찾을 수 없습니다.\"\n",
        "            }\n",
        "\n",
        "        # 등록된 얼굴과 비교\n",
        "        best_match = None\n",
        "        best_similarity = 0\n",
        "\n",
        "        for file in REGISTERED_FACES_DIR.glob(\"*.pkl\"):\n",
        "            with open(file, \"rb\") as f:\n",
        "                registered_data = pickle.load(f)\n",
        "                registered_embedding = registered_data[\"embedding\"]\n",
        "                similarity = compare_embeddings(embedding, registered_embedding)\n",
        "\n",
        "                if similarity > best_similarity:\n",
        "                    best_similarity = similarity\n",
        "                    best_match = registered_data[\"name\"]\n",
        "\n",
        "        # 결과 반환\n",
        "        if best_similarity > 0.85:  # 85% 이상 유사도로 인식\n",
        "            # 얼굴 메시 정보 추가\n",
        "            results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "            num_landmarks = len(results.multi_face_landmarks[0].landmark) if results.multi_face_landmarks else 0\n",
        "\n",
        "            return {\n",
        "                **detection_info,\n",
        "                \"recognized\": True,\n",
        "                \"name\": best_match,\n",
        "                \"confidence\": float(best_similarity),\n",
        "                \"num_landmarks\": num_landmarks,\n",
        "                \"message\": f\"{best_match}님으로 인식되었습니다.\"\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                **detection_info,\n",
        "                \"recognized\": False,\n",
        "                \"confidence\": float(best_similarity),\n",
        "                \"message\": \"등록되지 않은 얼굴입니다.\"\n",
        "            }\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/detect_objects\")\n",
        "async def detect_objects_api(image: UploadFile = File(...)):\n",
        "    \"\"\"객체 감지 API\"\"\"\n",
        "    try:\n",
        "        # 이미지 읽기\n",
        "        contents = await image.read()\n",
        "        nparr = np.frombuffer(contents, np.uint8)\n",
        "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # 객체 감지\n",
        "        detected_objects = detect_objects(img)\n",
        "\n",
        "        return {\n",
        "            \"objects_detected\": len(detected_objects) > 0,\n",
        "            \"num_objects\": len(detected_objects),\n",
        "            \"objects\": detected_objects,\n",
        "            \"message\": f\"{len(detected_objects)}개의 객체가 감지되었습니다.\" if detected_objects else \"감지된 객체가 없습니다.\"\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/recognize_all\")\n",
        "async def recognize_all(image: UploadFile = File(...)):\n",
        "    \"\"\"얼굴과 객체를 모두 인식하는 API\"\"\"\n",
        "    try:\n",
        "        # 이미지 읽기\n",
        "        contents = await image.read()\n",
        "        nparr = np.frombuffer(contents, np.uint8)\n",
        "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # 얼굴 인식\n",
        "        face_info = {}\n",
        "        detection_info = get_face_detection_info(img)\n",
        "        face_info.update(detection_info)\n",
        "\n",
        "        embedding = extract_face_embedding(img)\n",
        "        if embedding is not None:\n",
        "            # 등록된 얼굴과 비교\n",
        "            best_match = None\n",
        "            best_similarity = 0\n",
        "\n",
        "            for file in REGISTERED_FACES_DIR.glob(\"*.pkl\"):\n",
        "                with open(file, \"rb\") as f:\n",
        "                    registered_data = pickle.load(f)\n",
        "                    registered_embedding = registered_data[\"embedding\"]\n",
        "                    similarity = compare_embeddings(embedding, registered_embedding)\n",
        "\n",
        "                    if similarity > best_similarity:\n",
        "                        best_similarity = similarity\n",
        "                        best_match = registered_data[\"name\"]\n",
        "\n",
        "            if best_similarity > 0.85:\n",
        "                results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "                num_landmarks = len(results.multi_face_landmarks[0].landmark) if results.multi_face_landmarks else 0\n",
        "\n",
        "                face_info.update({\n",
        "                    \"recognized\": True,\n",
        "                    \"name\": best_match,\n",
        "                    \"confidence\": float(best_similarity),\n",
        "                    \"num_landmarks\": num_landmarks\n",
        "                })\n",
        "            else:\n",
        "                face_info.update({\n",
        "                    \"recognized\": False,\n",
        "                    \"confidence\": float(best_similarity)\n",
        "                })\n",
        "        else:\n",
        "            face_info.update({\"recognized\": False})\n",
        "\n",
        "        # 객체 감지\n",
        "        detected_objects = detect_objects(img)\n",
        "\n",
        "        return {\n",
        "            \"face_info\": face_info,\n",
        "            \"objects_info\": {\n",
        "                \"objects_detected\": len(detected_objects) > 0,\n",
        "                \"num_objects\": len(detected_objects),\n",
        "                \"objects\": detected_objects\n",
        "            },\n",
        "            \"message\": f\"얼굴: {'감지됨' if face_info.get('face_detected') else '미감지'}, 객체: {len(detected_objects)}개 감지\"\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    \"\"\"헬스체크 엔드포인트\"\"\"\n",
        "    return {\"status\": \"healthy\"}\n",
        "\n",
        "# 메인 페이지 라우트\n",
        "@app.get(\"/\")\n",
        "async def read_index():\n",
        "    return FileResponse('www/index.html')\n",
        "\n",
        "# Static 파일 설정 - API 엔드포인트 정의 후에 마운트\n",
        "app.mount(\"/static\", StaticFiles(directory=\"www\"), name=\"static\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4is496SvcdI",
        "outputId": "2c39296e-eb41-462f-e7ee-bec984df93e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test YOLO download only\n",
        "download_yolo_files()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "KdnTcIN792pi",
        "outputId": "c138c384-5c62-42be-cd52-679495ac127e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'download_yolo_files' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-843ecac27978>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test YOLO download only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdownload_yolo_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'download_yolo_files' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_server.py\n",
        "import subprocess\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import os\n",
        "\n",
        "# ngrok 터널 생성\n",
        "http_tunnel = ngrok.connect(8000)\n",
        "print(f\"ngrok 터널이 생성되었습니다: {http_tunnel.public_url}\")\n",
        "\n",
        "# 환경 변수로 공개 URL 전달 (선택사항)\n",
        "os.environ['PUBLIC_URL'] = http_tunnel.public_url\n",
        "\n",
        "try:\n",
        "    # FastAPI 서버 실행\n",
        "    config = uvicorn.Config(\n",
        "        \"app:app\",\n",
        "        host=\"0.0.0.0\",\n",
        "        port=8000,\n",
        "        reload=False,\n",
        "        log_level=\"info\"\n",
        "    )\n",
        "    server = uvicorn.Server(config)\n",
        "    server.run()\n",
        "except KeyboardInterrupt:\n",
        "    # 종료 시 정리\n",
        "    ngrok.kill()\n",
        "    print(\"서버가 종료되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUApq4B5vlR4",
        "outputId": "45e1f1b3-fa5b-4744-86c4-2db7a78f11a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run_server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn pyngrok mediapipe opencv-python-headless pillow numpy python-multipart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Uh2PvVTGvnZk",
        "outputId": "c936c90c-55b9-474a-b08f-fd5b6041b7a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.8)\n",
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.7)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_server.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BGlRkG00vpYU",
        "outputId": "43abfa48-5136-498b-f761-9f3a81e4e499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok 터널이 생성되었습니다: https://a89e-34-19-6-147.ngrok-free.app\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/run_server.py\", line 24, in <module>\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 70, in serve\n",
            "    await self._serve(sockets)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 77, in _serve\n",
            "    config.load()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/config.py\", line 435, in load\n",
            "    self.loaded_app = import_from_string(self.app)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/importer.py\", line 19, in import_from_string\n",
            "    module = importlib.import_module(module_str)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 936, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1004, in source_to_code\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/content/app.py\", line 49\n",
            "    if not os.path.exists(file_path):\n",
            "    ^\n",
            "IndentationError: expected an indented block after 'for' statement on line 48\n"
          ]
        }
      ]
    }
  ]
}